{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython\n",
    "import IPython.display as ipd \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioGan import *\n",
    "from ganSetup import *\n",
    "from ganModels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "    \n",
    "print('Using device: ', device)\n",
    "\n",
    "config = GANConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOSEI Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.DATASET_PATH + \"mosei_train_updated.csv\")\n",
    "test  = pd.read_csv(config.DATASET_PATH + \"mosei_test_updated.csv\")\n",
    "print(train.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of samples for each label\n",
    "category_group = train.groupby('label').size()\n",
    "\n",
    "# Sort the counts\n",
    "sorted_category_group = category_group.sort_values()\n",
    "\n",
    "# Plot the number of audio samples per category\n",
    "plt.figure(figsize=(16, 10))\n",
    "plot = sorted_category_group.plot(kind='bar', title=\"Number of Audio Samples per Category\")\n",
    "plot.set_xlabel(\"Category\")\n",
    "plot.set_ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = config.DATASET_PATH + \"audio_train/_4K620KW_Is_30.5020_36.0620.wav\"   # Hi-hat\n",
    "data, _ = librosa.core.load(fname, sr=config.SAMPLE_RATE, res_type='kaiser_fast')\n",
    "print(\"Total samples (frames) = \", data.shape)\n",
    "print(data)\n",
    "IPython.display.display(ipd.Audio(filename=fname))\n",
    "plt.plot(data, '-', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:2*config.SAMPLE_RATE]\n",
    "mfcc = librosa.feature.mfcc(y=data, sr = config.SAMPLE_RATE, n_mfcc=40)\n",
    "mel = librosa.feature.melspectrogram(y=data, sr=config.SAMPLE_RATE)\n",
    "# Display the shapes of the computed features\n",
    "print(\"MFCC Shape: \", mfcc.shape)\n",
    "print(\"Mel Spectrogram Shape: \", mel.shape)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))  # Create a figure with two subplots\n",
    "\n",
    "# Display MFCC\n",
    "axs[0].imshow(mfcc, cmap='hot', interpolation='nearest', aspect='auto', origin='lower')\n",
    "axs[0].set_title('MFCC')\n",
    "\n",
    "# Convert Mel Spectrogram to decibels and display\n",
    "mel_dB = librosa.power_to_db(mel, ref=np.max)\n",
    "img = axs[1].imshow(mel_dB, cmap='hot', interpolation='nearest', aspect='auto', origin='lower')\n",
    "fig.colorbar(img, ax=axs[1], format='%+2.0f dB')\n",
    "axs[1].set_title('Mel Spectrogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = discriminator(config.AUDIO_SHAPE)\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator(config.NOISE_DIM, config.AUDIO_SHAPE)\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = stacked_G_D(g,d)\n",
    "s.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = encoder(config.AUDIO_SHAPE, config.ENCODE_SIZE)\n",
    "a = autoEncoder(e, g)\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGan = AudioGAN(label = config.LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087\n",
      "\u001b[1m 1/66\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:49\u001b[0m 36s/step - accuracy: 0.0000e+00 - loss: 1.7397"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(len(myGan.trainData))\n",
    "batch=32\n",
    "if len(myGan.trainData) > batch:  # Ensure there are more samples than the batch size\n",
    "    myGan.train_autoencoder(myGan.trainData ,epochs=1, batch_size=32)\n",
    "else:\n",
    "    print(\"Not enough data to form a batch.\")\n",
    "end = time.time()\n",
    "\n",
    "if len(myGan.trainData) > batch:\n",
    "    total = round(end - start, 2)\n",
    "    print(\"\\nExecution Time: \", total, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "INDEX = 11\n",
    "sample = myGan.trainData[INDEX]\n",
    "\n",
    "print(\"Original:\")\n",
    "IPython.display.display(ipd.Audio(data=sample, rate=config.SAMPLE_RATE))\n",
    "sf.write(config.AUTO_ENCODER_PATH + \"AE_Original_\" + config.LABEL + \".wav\", sample, config.SAMPLE_RATE)\n",
    "\n",
    "result = myGan.autoencoder.predict(sample.reshape((1, config.AUDIO_SHAPE))).flatten()\n",
    "\n",
    "print(\"Result:\")\n",
    "IPython.display.display(ipd.Audio(data=result, rate=config.SAMPLE_RATE))\n",
    "sf.write(config.AUTO_ENCODER_PATH + \"AE_Result_\" + config.LABEL + \".wav\", result, config.SAMPLE_RATE)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "Original = fig.add_subplot(1, 2, 1)\n",
    "Result = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "Original.set_title('Original')\n",
    "Result.set_title('Result')\n",
    "\n",
    "Original.plot(sample, '.', color='blue')\n",
    "Result.plot(result, '.', color='green')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(config.PICTURE_PATH + \"AE_Compare_\" + config.LABEL + \".png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig      = plt.figure(figsize=(1, 2))\n",
    "OriginalZ = fig.add_subplot(1, 2, 1)\n",
    "ResultZ   = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "OriginalZ.set_title('Original Zoom')\n",
    "ResultZ.set_title('Result Zoom')\n",
    "\n",
    "ZoomInit = 40000\n",
    "ZoomSize = 100\n",
    "\n",
    "OriginalZ.plot(sample[ZoomInit:ZoomInit+ZoomSize], '.')\n",
    "OriginalZ.plot(sample[ZoomInit:ZoomInit+ZoomSize], '-')\n",
    "ResultZ.plot(result[ZoomInit:ZoomInit+ZoomSize], '.')                \n",
    "ResultZ.plot(result[ZoomInit:ZoomInit+ZoomSize], '-')\n",
    "\n",
    "plt.gcf().set_size_inches(30, 10)\n",
    "plt.subplots_adjust(wspace=0.1,hspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(config.PICTURE_PATH + \"AE_CompareZ_\" + config.LABEL + \".png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "myGan.train_gan(epochs = 5, batch = 32, save_interval = 2)\n",
    "end = time.time()\n",
    "total = round(end - start, 2)\n",
    "print(\"Execution Time: \", total, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator and Generator Loss over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Losses over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.plot(myGan.disLossHist, '-', label = 'Discriminator', color = 'blue')\n",
    "plt.plot(myGan.genLossHist, '-', label = 'Generator',     color = 'red')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 5)\n",
    "plt.savefig(config.PICTURE_PATH + \"D_G_Loss.png\", bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin, col = 1, 6\n",
    "fig = plt.figure(figsize=(lin, col))\n",
    "subPlotS = []\n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        subPlotS.append(fig.add_subplot(lin , col, (i*col)+j+1))\n",
    "        \n",
    "        \n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        gen_noise = np.random.normal(0, 1, (1,config.NOISE_DIM))\n",
    "        gen_test = myGan.gen.predict(gen_noise).flatten()\n",
    "        #IPython.display.display(ipd.Audio(data=gen_test, rate=SAMPLE_RATE))\n",
    "        subPlotS[(i*col)+j].plot(gen_test, '.', color='red')\n",
    "\n",
    "\n",
    "\n",
    "plt.gcf().set_size_inches(80, 10)\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(config.PICTURE_PATH + \"Generated_\"+ config.LABEL + \".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin, col = 1, 6\n",
    "fig = plt.figure(figsize=(lin, col))\n",
    "subPlotS = []\n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        subPlotS.append(fig.add_subplot(lin , col, (i*col)+j+1))\n",
    "        \n",
    "        \n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        random_index = np.random.randint(0, len(myGan.trainData))\n",
    "        original = myGan.trainData[random_index]\n",
    "        #IPython.display.display(ipd.Audio(data=original, rate=SAMPLE_RATE))\n",
    "        subPlotS[(i*col)+j].plot(original, '.', color='blue')\n",
    "\n",
    "plt.gcf().set_size_inches(80, 10)\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(config.PICTURE_PATH + \"Originals_\"+ config.LABEL + \".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Conv 1D Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs: lin x col = filters\n",
    "lin, col = 8, 4\n",
    "\n",
    "kernelSize = len(myGan.dis.layers[1].get_weights()[0])\n",
    "filters    = len(myGan.dis.layers[1].get_weights()[0][0][0])\n",
    "\n",
    "print(\"Filters: \", filters)\n",
    "print(\"Kernel Size: \", kernelSize)\n",
    "\n",
    "W = myGan.dis.layers[1].get_weights()[0].reshape(filters,1,kernelSize)\n",
    "\n",
    "print(W.shape)\n",
    "fig = plt.figure(figsize=(lin, col))\n",
    "subPlotS = []\n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        subPlotS.append(fig.add_subplot(lin , col, (i*col)+j+1))\n",
    "        \n",
    "layNum = 1     \n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        convFilter = W[(i*col)+j][0]\n",
    "        subPlotS[(i*col)+j].plot(convFilter, '.-', color='purple')\n",
    "\n",
    "plt.gcf().set_size_inches(20, 20)\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs: lin x col = filters\n",
    "lin, col = 4, 4\n",
    "\n",
    "kernelSize = len(myGan.gen.layers[4].get_weights()[0])\n",
    "filters    = len(myGan.gen.layers[4].get_weights()[0][0][0])\n",
    "\n",
    "print(\"Filters: \", filters)\n",
    "print(\"Kernel Size: \", kernelSize)\n",
    "\n",
    "W = myGan.gen.layers[4].get_weights()[0].reshape(filters,1,kernelSize)\n",
    "\n",
    "print(W.shape)\n",
    "fig = plt.figure(figsize=(lin, col))\n",
    "subPlotS = []\n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        subPlotS.append(fig.add_subplot(lin , col, (i*col)+j+1))\n",
    "        \n",
    "layNum = 1     \n",
    "for i in range(lin):\n",
    "    for j in range(col):\n",
    "        convFilter = W[(i*col)+j][0]\n",
    "        subPlotS[(i*col)+j].plot(convFilter, '.-', color='purple')\n",
    "\n",
    "plt.gcf().set_size_inches(20, 20)\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
