{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDIO GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioGan import AudioGAN\n",
    "from ganSetup import GANConfig\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "config = GANConfig()\n",
    "myGan = AudioGAN(label = config.LABEL, load= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOENCODER PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 11\n",
    "sample = myGan.testData[INDEX]\n",
    "\n",
    "print(\"Original:\")\n",
    "IPython.display.display(ipd.Audio(data=sample, rate=config.SAMPLE_RATE))\n",
    "sf.write(config.AUTO_ENCODER_PATH + \"AE_Original_test_\" + config.LABEL + \".wav\", sample, config.SAMPLE_RATE)\n",
    "\n",
    "result = myGan.autoencoder.predict(sample.reshape((1, config.AUDIO_SHAPE))).flatten()\n",
    "\n",
    "sf.write(\"AE_output.wav\", result, 16000)\n",
    "\n",
    "\n",
    "print(\"Result:\")\n",
    "IPython.display.display(ipd.Audio(data=result, rate=config.SAMPLE_RATE))\n",
    "sf.write(config.AUTO_ENCODER_PATH + \"AE_Generated_test_\" + config.LABEL + \".wav\", result, config.SAMPLE_RATE)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "Original = fig.add_subplot(1, 2, 1)\n",
    "Result = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "Original.set_title('Original')\n",
    "Result.set_title('Result')\n",
    "\n",
    "Original.plot(sample, '.', color='blue')\n",
    "Result.plot(result, '.', color='green')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(config.PICTURE_PATH + \"AE_Compare_test_\" + config.LABEL + \".png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATOR PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf  # Assuming you have the soundfile library installed\n",
    "import os\n",
    "\n",
    "# Load models\n",
    "encoder_path = os.path.join(myGan.model_path, 'encoder.keras')\n",
    "encoder = load_model(encoder_path)\n",
    "generator_path = os.path.join(myGan.model_path, 'generator.keras')\n",
    "generator = load_model(generator_path)\n",
    "\n",
    "# Function to predict using encoder and generator\n",
    "def generate_audio_from_real(real_audio):\n",
    "    # Assuming real_audio is preprocessed and shaped correctly [(1, audio_length)]\n",
    "    latent_vector = encoder.predict(real_audio.reshape(1, -1))\n",
    "    generated_audio = generator.predict(latent_vector).flatten()\n",
    "\n",
    "    # Display and save the audio\n",
    "    print(\"Original Audio:\")\n",
    "    ipd.display(ipd.Audio(data=real_audio.flatten(), rate=config.SAMPLE_RATE))\n",
    "    sf.write(config.AUTO_ENCODER_PATH + \"Gen_Original_test_\" + config.LABEL + \".wav\", real_audio.flatten(), config.SAMPLE_RATE)\n",
    "\n",
    "    print(\"Generated Audio:\")\n",
    "    ipd.display(ipd.Audio(data=generated_audio, rate=config.SAMPLE_RATE))\n",
    "    sf.write(config.AUTO_ENCODER_PATH + \"Gen_Generated_test_\" + config.LABEL + \".wav\", generated_audio, config.SAMPLE_RATE)\n",
    "\n",
    "    # Plot the original and generated audio waveforms\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    Original = fig.add_subplot(1, 2, 1)\n",
    "    Result = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    Original.set_title('Original')\n",
    "    Result.set_title('Generated')\n",
    "\n",
    "    Original.plot(real_audio.flatten(), '.', color='blue')\n",
    "    Result.plot(generated_audio, '.', color='green')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot\n",
    "    fig.savefig(config.PICTURE_PATH + \"Gen_Compare_test_\" + config.LABEL + \".png\", bbox_inches=\"tight\")\n",
    "\n",
    "    return generated_audio\n",
    "\n",
    "# Example usage\n",
    "INDEX = 10\n",
    "real_audio = myGan.testData[INDEX]  # Replace this with an actual audio sample\n",
    "generated_audio = generate_audio_from_real(real_audio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
