# Project Architecture
![image](https://github.com/Guneshwar24/Audio_Generation_emotion/assets/43294135/07517137-d251-4ecb-b2f2-0419fbf977f6)

# Audio_Generation
Generate new audio samples using GANs and using Autoencoder as baseline.

#Models
Download the models from link below and place them in the models folder in the repo.
https://hioa365-my.sharepoint.com/:f:/g/personal/guman4575_oslomet_no/ErAeH_H71uVMigPFtPm661QBGb9MRwA9r7GGxXsMMlLOFA?e=lJkfE8

# Dataset 
First, the dataset from CMU-MOSEI is present in "Dataset" in the same directory of this repository. It is cleaned as well as manipulated to fit into suitably.

# Install All Dependencies
install dependencies from requirements.txt
>> pip install -r requirements.txt

# Run
Run test.ipynb jupyter notebok:  for all things experimental and checking predictions for the GAN models 

# Architecture

Generator
![image](https://github.com/Guneshwar24/Audio_Generation_emotion/assets/43294135/46f51d6a-4a60-445a-8566-9944fbf1ee1e)

Discriminator
![image](https://github.com/Guneshwar24/Audio_Generation_emotion/assets/43294135/e0ae1ab8-ce15-4667-befd-e5075528b696)

# Classifier repository
https://github.com/zamud3164/Emotion_Recognition


